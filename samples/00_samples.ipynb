{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62878f1b",
   "metadata": {},
   "source": [
    "# XLSR- 53 model finetuned on Common voice german dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec309461",
   "metadata": {},
   "source": [
    "### XLSR-Wav2Vec2 is a speech model\n",
    "1. It accepts a float array (raw waveform) of the speech signal.\n",
    "2. The model was trained using connectionist temporal classification (CTC)\n",
    "3. The model output has to be decoded using Wav2Vec2CTCTokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a69f2",
   "metadata": {},
   "source": [
    "- In this notebook we have compared the Predicted and Reference Transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f7d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Libraries\n",
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38ed0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (/home/iqbalc/.cache/huggingface/datasets/common_voice/de/6.1.0/a1dc74461f6c839bfe1e8cf1262fd4cf24297e3fbd4087a711bd090779023a5e)\n"
     ]
    }
   ],
   "source": [
    "#Loading the data, processor and model\n",
    "test_dataset = load_dataset(\"common_voice\", \"de\", split=\"test[:4%]\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-xlsr-53-german\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-xlsr-53-german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c798208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampling the audio to 16000Hz\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0f2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the datasets.\n",
    "# We need to read the aduio files as arrays\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "        speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "        batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47b44993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180247481fb0456fab8afb18c6456bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
    "inputs = processor(test_dataset[:10][\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24b32418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store logits (non-normalized predictions)\n",
    "with torch.no_grad():\n",
    "        logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bc21598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predicted calues\n",
    "predicted_ids = torch.argmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81681533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['mückenstiche sollte man nicht aufkratzen', 'ist diese leitung sicher', 'die ratten verlassen das segene schif', 'ich habe eine neue arbeit', 'was sieht kamera eins gerade', 'was für einen angeber dachte horst im stillen', 'rückgängig machen', 'war die intigration erfolgreich', 'welche distripition mit klarzeit unterstützungen', 'lasst uns noch pabrika in den salat schnipseln']\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction:\", processor.batch_decode(predicted_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f43fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: ['Mückenstiche sollte man nicht aufkratzen.', 'Ist diese Leitung sicher?', 'Die Ratten verlassen das sinkende Schiff.', 'Ich habe eine neue Arbeit.', 'Was sieht Kamera Eins gerade?', '\"Was für ein Angeber\", dachte Horst im Stillen.', 'Rückgängig machen.', 'War die Integration erfolgreich?', 'Welche Distribution mit Langzeitunterstützung nutzt du am liebsten?', 'Lass uns noch Paprika in den Salat schnipseln.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Reference:\", test_dataset[:10][\"sentence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9792ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1840497608826e95edb9ca3288ed76e181d972ed8c044b13b4557a573be3002"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
